{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Member 1: Logistic Regression\n",
        "## Logistic Regression with Multiple Embeddings\n",
        "\n",
        "**Team Member:** Member 1\n",
        "**Model:** Logistic Regression\n",
        "**Embeddings:** TF-IDF, Skip-gram, CBOW\n",
        "\n",
        "---\n",
        "\n",
        "## Objectives\n",
        "1. Implement Logistic Regression for spam classification\n",
        "2. Train with at least 3 different embeddings\n",
        "3. Perform hyperparameter tuning\n",
        "4. Document all experiments systematically\n",
        "5. Save results for team comparison\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "import time\n",
        "import sys\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append('../src')\n",
        "\n",
        "# Import custom modules\n",
        "from preprocessing import TextPreprocessor\n",
        "from embeddings import TFIDFEmbedding, Word2VecEmbedding, GloVeEmbedding, FastTextEmbedding\n",
        "from evaluation import ModelEvaluator\n",
        "from utils import set_seed, print_data_info, save_model\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "set_seed(42)\n",
        "\n",
        "print('âœ“ Setup complete!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load preprocessed data from shared exploration notebook\n",
        "df = pd.read_csv('../data/processed/spam_cleaned.csv')\n",
        "\n",
        "# OR load raw and preprocess\n",
        "# df = pd.read_csv('../data/raw/spam.csv', encoding='latin-1')\n",
        "# preprocessor = TextPreprocessor()\n",
        "# df = preprocessor.preprocess_dataframe(df, 'v2', 'cleaned_text')\n",
        "\n",
        "print(f'Dataset shape: {df.shape}')\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Experiment 1: Logistic Regression + TF-IDF\n",
        "\n",
        "**Rationale:** TF-IDF is a traditional sparse representation that works well with...\n",
        "\n",
        "**Citation:** [Add relevant paper citation here]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare TF-IDF embeddings\n",
        "from embeddings import TFIDFEmbedding\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['cleaned_text'], df['label'],\n",
        "    test_size=0.2, random_state=42, stratify=df['label']\n",
        ")\n",
        "\n",
        "# Create TF-IDF features\n",
        "tfidf = TFIDFEmbedding(max_features=5000)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train.tolist())\n",
        "X_test_tfidf = tfidf.transform(X_test.tolist())\n",
        "\n",
        "print(f'TF-IDF shape: {X_train_tfidf.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Logistic Regression with TF-IDF\n",
        "# TODO: Implement your Logistic Regression model here\n",
        "\n",
        "# Example for Logistic Regression:\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Example for RNN/LSTM/GRU:\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
        "# model = Sequential([...])\n",
        "\n",
        "# Training\n",
        "start_time = time.time()\n",
        "# model.fit(X_train_tfidf, y_train)\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Predictions\n",
        "# y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "print(f'Training time: {training_time:.2f}s')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate Model\n",
        "evaluator = ModelEvaluator(class_names=['ham', 'spam'])\n",
        "\n",
        "# metrics = evaluator.evaluate(\n",
        "#     y_test, y_pred,\n",
        "#     model_name='Logistic Regression',\n",
        "#     embedding_name='TF-IDF',\n",
        "#     training_time=training_time\n",
        "# )\n",
        "\n",
        "# evaluator.print_metrics(metrics)\n",
        "# evaluator.plot_confusion_matrix(\n",
        "#     y_test, y_pred,\n",
        "#     title='Logistic Regression + TF-IDF - Confusion Matrix',\n",
        "#     save_path='../results/figures/member1_tfidf_cm.png'\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Experiment 2: Logistic Regression + Skip-gram (Word2Vec)\n",
        "\n",
        "**Rationale:** Skip-gram embeddings capture semantic relationships...\n",
        "\n",
        "**Citation:** Mikolov et al. (2013)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare Skip-gram embeddings\n",
        "# TODO: Implement Skip-gram training\n",
        "# Tokenize texts\n",
        "# Train Word2Vec with sg=1\n",
        "# Transform to document vectors\n",
        "# Train model\n",
        "# Evaluate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Experiment 3: Logistic Regression + CBOW (Word2Vec)\n",
        "\n",
        "**Rationale:** CBOW is faster to train and works well for...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare CBOW embeddings\n",
        "# TODO: Implement CBOW training (sg=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Results Summary and Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save all results to CSV\n",
        "# evaluator.save_results_table(\n",
        "#     filepath='../results/tables/member1_results.csv'\n",
        "# )\n",
        "\n",
        "# Create comparison plots\n",
        "# Plot bar chart comparing embeddings for this model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Hyperparameter Tuning (Optional but Recommended)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform grid search or random search for best hyperparameters\n",
        "# Example:\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "# param_grid = {...}\n",
        "# grid_search = GridSearchCV(model, param_grid, cv=5)\n",
        "# grid_search.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Conclusions and Observations\n",
        "\n",
        "**Key Findings:**\n",
        "- Best performing embedding: [Fill in]\n",
        "- Why it performed better: [Discuss]\n",
        "- Comparison with team: [After seeing other results]\n",
        "\n",
        "**Limitations:**\n",
        "- [Discuss limitations]\n",
        "\n",
        "**Future Work:**\n",
        "- [Suggestions for improvement]\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
