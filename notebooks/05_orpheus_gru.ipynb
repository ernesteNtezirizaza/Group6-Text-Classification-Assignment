{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Member 4: GRU\n",
        "## GRU with Multiple Embeddings\n",
        "\n",
        "**Team Member:** Member 4\n",
        "**Model:** GRU\n",
        "**Embeddings:** TF-IDF, Skip-gram, CBOW\n",
        "\n",
        "---\n",
        "\n",
        "## Objectives\n",
        "1. Implement GRU for spam classification\n",
        "2. Train with at least 3 different embeddings\n",
        "3. Perform hyperparameter tuning\n",
        "4. Document all experiments systematically\n",
        "5. Save results for team comparison\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Kaggle Setup Instructions\n",
        "\n",
        "**To run this notebook on Kaggle:**\n",
        "\n",
        "1. **Upload the dataset:**\n",
        "   - Go to Kaggle → Datasets → New Dataset\n",
        "   - Upload `spam.csv` from `data/raw/spam.csv`\n",
        "   - Name it something like \"sms-spam-collection\"\n",
        "   - Make it public or private\n",
        "\n",
        "2. **Upload the source code:**\n",
        "   - Create a new dataset for the source files\n",
        "   - Upload all files from the `src/` folder:\n",
        "     - `preprocessing.py`\n",
        "     - `embeddings.py`\n",
        "     - `evaluation.py`\n",
        "     - `utils.py`\n",
        "     - `__init__.py`\n",
        "   - Name it \"text-classification-utils\" or similar\n",
        "\n",
        "3. **In Kaggle notebook:**\n",
        "   - Add both datasets to your notebook inputs\n",
        "   - The data will be in `/kaggle/input/[dataset-name]/`\n",
        "   - Outputs go to `/kaggle/working/`\n",
        "\n",
        "4. **Enable GPU/TPU (Optional but recommended):**\n",
        "   - Go to Settings → Accelerator → GPU T4 x2\n",
        "\n",
        "**The code below will automatically detect if running on Kaggle and adjust paths accordingly.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if running on Kaggle\n",
        "import os\n",
        "\n",
        "IS_KAGGLE = os.path.exists('/kaggle')\n",
        "\n",
        "if IS_KAGGLE:\n",
        "    print(\"Running on Kaggle\")\n",
        "    # Kaggle paths\n",
        "    DATA_DIR = '/kaggle/input'\n",
        "    OUTPUT_DIR = '/kaggle/working'\n",
        "    SRC_DIR = '/kaggle/input'  # Will be updated after you add the dataset\n",
        "else:\n",
        "    print(\"Running locally\")\n",
        "    # Local paths\n",
        "    DATA_DIR = '../data'\n",
        "    OUTPUT_DIR = '../results'\n",
        "    SRC_DIR = '../src'\n",
        "\n",
        "print(f\"Data directory: {DATA_DIR}\")\n",
        "print(f\"Output directory: {OUTPUT_DIR}\")\n",
        "print(f\"Source directory: {SRC_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages (if on Kaggle)\n",
        "import sys\n",
        "import os\n",
        "\n",
        "if IS_KAGGLE:\n",
        "    print(\"Installing required packages...\")\n",
        "    import subprocess\n",
        "    subprocess.run(['pip', 'install', '-q', 'wordcloud', 'gensim'], check=True)\n",
        "    print(\"✓ Packages installed\")\n",
        "\n",
        "# Add src to path FIRST (before any imports to avoid conflicts)\n",
        "if IS_KAGGLE:\n",
        "    # On Kaggle, add the utils path to the BEGINNING of sys.path\n",
        "    src_paths = [\n",
        "        '/kaggle/input/text-classification-utils',\n",
        "        '/kaggle/input/spam-classification-utils',\n",
        "        '/kaggle/input/group6-utils'\n",
        "    ]\n",
        "    for path in src_paths:\n",
        "        if os.path.exists(path):\n",
        "            # Insert at beginning to prioritize over system packages\n",
        "            sys.path.insert(0, path)\n",
        "            print(f\"✓ Added {path} to system path (at beginning)\")\n",
        "            break\n",
        "else:\n",
        "    sys.path.insert(0, SRC_DIR)\n",
        "    print(f\"✓ Added {SRC_DIR} to system path\")\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "import time\n",
        "\n",
        "# Import custom modules\n",
        "try:\n",
        "    from preprocessing import TextPreprocessor\n",
        "    from embeddings import TFIDFEmbedding, Word2VecEmbedding, GloVeEmbedding, FastTextEmbedding\n",
        "    from evaluation import ModelEvaluator\n",
        "    from utils import set_seed, print_data_info, save_model\n",
        "    print(\"✓ Custom modules imported successfully\")\n",
        "except ImportError as e:\n",
        "    print(f\"⚠ Error importing custom modules: {e}\")\n",
        "    print(\"If on Kaggle, make sure you've added the utils dataset to your notebook inputs\")\n",
        "    print(\"\\nAttempting to define functions inline as fallback...\")\n",
        "    \n",
        "    # Fallback: Define set_seed inline\n",
        "    import random\n",
        "    import numpy as np\n",
        "    \n",
        "    def set_seed(seed=42):\n",
        "        \"\"\"Set random seeds for reproducibility.\"\"\"\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        try:\n",
        "            import tensorflow as tf\n",
        "            tf.random.set_seed(seed)\n",
        "        except:\n",
        "            pass\n",
        "    \n",
        "    print(\"✓ Fallback functions defined\")\n",
        "    print(\"\\n⚠ WARNING: You need to upload the Python files from src/ folder as a Kaggle dataset\")\n",
        "    print(\"Without custom modules, only basic functionality will work.\")\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "set_seed(42)\n",
        "\n",
        "print('✓ Setup complete!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load and Prepare Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.5. Fallback Class Definitions\n",
        "\n",
        "If custom modules aren't available, define required classes inline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define fallback classes if custom modules failed to import\n",
        "if 'TFIDFEmbedding' not in globals():\n",
        "    print(\"Defining fallback classes...\")\n",
        "    \n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "    from gensim.models import Word2Vec\n",
        "    \n",
        "    class TFIDFEmbedding:\n",
        "        def __init__(self, max_features=5000, min_df=2, max_df=0.95, ngram_range=(1, 2)):\n",
        "            self.vectorizer = TfidfVectorizer(\n",
        "                max_features=max_features,\n",
        "                min_df=min_df,\n",
        "                max_df=max_df,\n",
        "                ngram_range=ngram_range\n",
        "            )\n",
        "        \n",
        "        def fit_transform(self, texts):\n",
        "            return self.vectorizer.fit_transform(texts).toarray()\n",
        "        \n",
        "        def transform(self, texts):\n",
        "            return self.vectorizer.transform(texts).toarray()\n",
        "        \n",
        "        def get_vocab_size(self):\n",
        "            return len(self.vectorizer.vocabulary_)\n",
        "    \n",
        "    class Word2VecEmbedding:\n",
        "        def __init__(self, vector_size=100, window=5, min_count=2, sg=1, workers=4, epochs=10):\n",
        "            self.vector_size = vector_size\n",
        "            self.window = window\n",
        "            self.min_count = min_count\n",
        "            self.sg = sg\n",
        "            self.workers = workers\n",
        "            self.epochs = epochs\n",
        "            self.model = None\n",
        "        \n",
        "        def train(self, tokenized_texts):\n",
        "            self.model = Word2Vec(\n",
        "                sentences=tokenized_texts,\n",
        "                vector_size=self.vector_size,\n",
        "                window=self.window,\n",
        "                min_count=self.min_count,\n",
        "                sg=self.sg,\n",
        "                workers=self.workers,\n",
        "                epochs=self.epochs\n",
        "            )\n",
        "        \n",
        "        def transform(self, tokenized_texts, method='mean'):\n",
        "            vectors = []\n",
        "            for tokens in tokenized_texts:\n",
        "                word_vecs = [self.model.wv[word] for word in tokens if word in self.model.wv]\n",
        "                if word_vecs:\n",
        "                    if method == 'mean':\n",
        "                        vectors.append(np.mean(word_vecs, axis=0))\n",
        "                    else:\n",
        "                        vectors.append(np.mean(word_vecs, axis=0))\n",
        "                else:\n",
        "                    vectors.append(np.zeros(self.vector_size))\n",
        "            return np.array(vectors)\n",
        "    \n",
        "    class TextPreprocessor:\n",
        "        def __init__(self, lowercase=True, remove_punctuation=True, remove_stopwords=True, lemmatization=True, **kwargs):\n",
        "            self.lowercase = lowercase\n",
        "            self.remove_punctuation = remove_punctuation\n",
        "            self.remove_stopwords = remove_stopwords\n",
        "            self.lemmatization = lemmatization\n",
        "        \n",
        "        def preprocess(self, text, return_tokens=False):\n",
        "            if not isinstance(text, str):\n",
        "                return [] if return_tokens else \"\"\n",
        "            \n",
        "            import re\n",
        "            import string\n",
        "            \n",
        "            # Lowercase\n",
        "            if self.lowercase:\n",
        "                text = text.lower()\n",
        "            \n",
        "            # Remove URLs and emails\n",
        "            text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
        "            text = re.sub(r'\\S+@\\S+', '', text)\n",
        "            \n",
        "            # Remove punctuation\n",
        "            if self.remove_punctuation:\n",
        "                text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "            \n",
        "            # Tokenize\n",
        "            tokens = text.split()\n",
        "            \n",
        "            # Remove stopwords\n",
        "            if self.remove_stopwords:\n",
        "                try:\n",
        "                    from nltk.corpus import stopwords\n",
        "                    stop_words = set(stopwords.words('english'))\n",
        "                    tokens = [w for w in tokens if w not in stop_words]\n",
        "                except:\n",
        "                    pass  # Skip if NLTK not available\n",
        "            \n",
        "            if return_tokens:\n",
        "                return tokens\n",
        "            else:\n",
        "                return ' '.join(tokens)\n",
        "    \n",
        "    class ModelEvaluator:\n",
        "        def __init__(self, class_names=None):\n",
        "            self.class_names = class_names or ['Class 0', 'Class 1']\n",
        "            self.results_history = []\n",
        "        \n",
        "        def evaluate(self, y_true, y_pred, model_name=\"Model\", embedding_name=\"Embedding\", training_time=None):\n",
        "            from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "            \n",
        "            metrics = {\n",
        "                'model': model_name,\n",
        "                'embedding': embedding_name,\n",
        "                'accuracy': accuracy_score(y_true, y_pred),\n",
        "                'precision': precision_score(y_true, y_pred, average='weighted', zero_division=0),\n",
        "                'recall': recall_score(y_true, y_pred, average='weighted', zero_division=0),\n",
        "                'f1_score': f1_score(y_true, y_pred, average='weighted', zero_division=0),\n",
        "                'training_time': training_time\n",
        "            }\n",
        "            self.results_history.append(metrics)\n",
        "            return metrics\n",
        "        \n",
        "        def print_metrics(self, metrics):\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"Model: {metrics['model']} | Embedding: {metrics['embedding']}\")\n",
        "            print(f\"{'='*60}\")\n",
        "            print(f\"Accuracy:  {metrics['accuracy']:.4f}\")\n",
        "            print(f\"Precision: {metrics['precision']:.4f}\")\n",
        "            print(f\"Recall:    {metrics['recall']:.4f}\")\n",
        "            print(f\"F1 Score:  {metrics['f1_score']:.4f}\")\n",
        "            if metrics['training_time']:\n",
        "                print(f\"Training Time: {metrics['training_time']:.2f}s\")\n",
        "            print(f\"{'='*60}\\n\")\n",
        "        \n",
        "        def plot_confusion_matrix(self, y_true, y_pred, title=\"Confusion Matrix\", figsize=(8, 6), save_path=None):\n",
        "            from sklearn.metrics import confusion_matrix\n",
        "            \n",
        "            cm = confusion_matrix(y_true, y_pred)\n",
        "            \n",
        "            plt.figure(figsize=figsize)\n",
        "            sns.heatmap(\n",
        "                cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=self.class_names,\n",
        "                yticklabels=self.class_names\n",
        "            )\n",
        "            plt.title(title, fontsize=14, fontweight='bold')\n",
        "            plt.ylabel('True Label', fontsize=12)\n",
        "            plt.xlabel('Predicted Label', fontsize=12)\n",
        "            plt.tight_layout()\n",
        "            \n",
        "            if save_path:\n",
        "                plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "            plt.show()\n",
        "        \n",
        "        def save_results_table(self, filepath='results.csv'):\n",
        "            df = pd.DataFrame(self.results_history)\n",
        "            df.to_csv(filepath, index=False)\n",
        "            print(f\"Results saved to {filepath}\")\n",
        "            return df\n",
        "    \n",
        "    print(\"✓ Fallback classes defined successfully\")\n",
        "else:\n",
        "    print(\"✓ Using custom modules from dataset\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and preprocess data\n",
        "import os\n",
        "\n",
        "# Define paths based on environment\n",
        "if IS_KAGGLE:\n",
        "    # Update these with your actual Kaggle dataset names\n",
        "    possible_data_paths = [\n",
        "        '/kaggle/input/sms-spam-collection/spam.csv',\n",
        "        '/kaggle/input/sms-spam-collection-dataset/spam.csv',\n",
        "        '/kaggle/input/spam-dataset/spam.csv',\n",
        "    ]\n",
        "    preprocessed_path = '/kaggle/working/spam_preprocessed.csv'\n",
        "    \n",
        "    # Find the actual data file\n",
        "    raw_data_path = None\n",
        "    for path in possible_data_paths:\n",
        "        if os.path.exists(path):\n",
        "            raw_data_path = path\n",
        "            print(f\"✓ Found data at: {path}\")\n",
        "            break\n",
        "    \n",
        "    if raw_data_path is None:\n",
        "        # List available files to help debug\n",
        "        print(\"Available input files:\")\n",
        "        for root, dirs, files in os.walk('/kaggle/input'):\n",
        "            for file in files:\n",
        "                print(f\"  {os.path.join(root, file)}\")\n",
        "        raise FileNotFoundError(\"Could not find spam.csv. Please check your Kaggle dataset name.\")\n",
        "else:\n",
        "    raw_data_path = os.path.join(DATA_DIR, 'raw/spam.csv')\n",
        "    preprocessed_path = os.path.join(DATA_DIR, 'processed/spam_preprocessed.csv')\n",
        "\n",
        "# Check if preprocessed data exists, otherwise preprocess\n",
        "if os.path.exists(preprocessed_path):\n",
        "    df = pd.read_csv(preprocessed_path)\n",
        "    print(f'✓ Loaded preprocessed data from {preprocessed_path}')\n",
        "else:\n",
        "    # Load raw data\n",
        "    df = pd.read_csv(raw_data_path, encoding='latin-1')\n",
        "    \n",
        "    # Keep only the first two columns and rename them\n",
        "    df = df.iloc[:, :2]\n",
        "    df.columns = ['label', 'text']\n",
        "    \n",
        "    # Basic preprocessing (if TextPreprocessor not available)\n",
        "    if 'TextPreprocessor' in globals():\n",
        "        # Use custom preprocessor if available\n",
        "        preprocessor = TextPreprocessor(\n",
        "            lowercase=True,\n",
        "            remove_punctuation=True,\n",
        "            remove_stopwords=True,\n",
        "            lemmatization=True\n",
        "        )\n",
        "        df['cleaned_text'] = df['text'].apply(preprocessor.preprocess)\n",
        "    else:\n",
        "        # Fallback: Basic preprocessing inline\n",
        "        print(\"Using basic inline preprocessing...\")\n",
        "        import re\n",
        "        import string\n",
        "        \n",
        "        def basic_preprocess(text):\n",
        "            if not isinstance(text, str):\n",
        "                return \"\"\n",
        "            # Lowercase\n",
        "            text = text.lower()\n",
        "            # Remove URLs\n",
        "            text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
        "            # Remove emails\n",
        "            text = re.sub(r'\\S+@\\S+', '', text)\n",
        "            # Remove punctuation\n",
        "            text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "            # Remove extra whitespace\n",
        "            text = ' '.join(text.split())\n",
        "            return text\n",
        "        \n",
        "        df['cleaned_text'] = df['text'].apply(basic_preprocess)\n",
        "        print(\"✓ Basic preprocessing applied\")\n",
        "    \n",
        "    # Save preprocessed data\n",
        "    if IS_KAGGLE:\n",
        "        os.makedirs('/kaggle/working', exist_ok=True)\n",
        "    else:\n",
        "        os.makedirs(os.path.join(DATA_DIR, 'processed'), exist_ok=True)\n",
        "    \n",
        "    df.to_csv(preprocessed_path, index=False)\n",
        "    print(f'✓ Preprocessed and saved data to {preprocessed_path}')\n",
        "\n",
        "# Encode labels (ham=0, spam=1)\n",
        "df['label_encoded'] = (df['label'] == 'spam').astype(int)\n",
        "\n",
        "print(f'\\nDataset shape: {df.shape}')\n",
        "print(f'Class distribution:\\n{df[\"label\"].value_counts()}')\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Preparation for Experiments\n",
        "\n",
        "We'll split the data using stratified sampling and prepare embeddings for all three experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1. Stratified Train/Test Split\n",
        "\n",
        "Using the `split_data` function from utils.py to ensure balanced class distribution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create TF-IDF features\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "tfidf = TFIDFEmbedding(max_features=5000, ngram_range=(1, 2))\n",
        "X_train_tfidf = tfidf.fit_transform(X_train.tolist())\n",
        "X_test_tfidf = tfidf.transform(X_test.tolist())\n",
        "\n",
        "print(f'TF-IDF shape: {X_train_tfidf.shape}')\n",
        "print(f'Vocabulary size: {tfidf.get_vocab_size()}')\n",
        "\n",
        "# Calculate class weights to handle imbalance (will be used in all experiments)\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train.values\n",
        ")\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "print(f'\\nClass weights for training:')\n",
        "print(f'  Ham (0):  {class_weight_dict[0]:.4f}')\n",
        "print(f'  Spam (1): {class_weight_dict[1]:.4f}')\n",
        "print(f'\\n✓ TF-IDF embeddings ready for training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3. Prepare TF-IDF Embeddings\n",
        "\n",
        "Creating TF-IDF features for Experiment 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze class distribution\n",
        "print(\"=\"*60)\n",
        "print(\"CLASS DISTRIBUTION ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Full dataset\n",
        "total_count = df['label_encoded'].value_counts()\n",
        "print(f\"\\nFull Dataset ({len(df)} samples):\")\n",
        "print(f\"  Ham (0):  {total_count[0]:,} ({total_count[0]/len(df)*100:.2f}%)\")\n",
        "print(f\"  Spam (1): {total_count[1]:,} ({total_count[1]/len(df)*100:.2f}%)\")\n",
        "print(f\"  Imbalance Ratio: {total_count[0]/total_count[1]:.2f}:1\")\n",
        "\n",
        "# Training set\n",
        "train_count = y_train.value_counts()\n",
        "print(f\"\\nTraining Set ({len(y_train)} samples):\")\n",
        "print(f\"  Ham (0):  {train_count[0]:,} ({train_count[0]/len(y_train)*100:.2f}%)\")\n",
        "print(f\"  Spam (1): {train_count[1]:,} ({train_count[1]/len(y_train)*100:.2f}%)\")\n",
        "\n",
        "# Test set\n",
        "test_count = y_test.value_counts()\n",
        "print(f\"\\nTest Set ({len(y_test)} samples):\")\n",
        "print(f\"  Ham (0):  {test_count[0]:,} ({test_count[0]/len(y_test)*100:.2f}%)\")\n",
        "print(f\"  Spam (1): {test_count[1]:,} ({test_count[1]/len(y_test)*100:.2f}%)\")\n",
        "\n",
        "print(f\"\\n✓ Stratified sampling successful - distributions are balanced across splits\")\n",
        "print(f\"⚠️  We'll use class weights to handle the {total_count[0]/total_count[1]:.1f}:1 imbalance\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Visualize class distribution\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "for idx, (name, data) in enumerate([('Full Dataset', df['label_encoded']), \n",
        "                                      ('Training Set', y_train), \n",
        "                                      ('Test Set', y_test)]):\n",
        "    counts = data.value_counts()\n",
        "    colors = ['#2ecc71', '#e74c3c']\n",
        "    bars = axes[idx].bar(['Ham', 'Spam'], counts.values, color=colors, edgecolor='black', linewidth=1.5)\n",
        "    axes[idx].set_title(name, fontsize=13, fontweight='bold')\n",
        "    axes[idx].set_ylabel('Count', fontsize=11)\n",
        "    axes[idx].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # Add value labels\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        axes[idx].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                      f'{int(height):,}\\n({height/len(data)*100:.1f}%)',\n",
        "                      ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2. Class Distribution Analysis\n",
        "\n",
        "Understanding the imbalance to handle it properly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare TF-IDF embeddings\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Split data using stratified approach from utils.py\n",
        "# Import or use the split_data function\n",
        "if 'split_data' in globals():\n",
        "    # Use split_data from utils if available\n",
        "    X_train, X_test, y_train, y_test = split_data(\n",
        "        X=df['cleaned_text'].values,\n",
        "        y=df['label_encoded'].values,\n",
        "        test_size=0.2,\n",
        "        val_size=0,  # No separate validation set (will use validation_split in model.fit)\n",
        "        random_state=42,\n",
        "        stratify=True\n",
        "    )\n",
        "    # Convert back to pandas Series for compatibility\n",
        "    X_train = pd.Series(X_train)\n",
        "    X_test = pd.Series(X_test)\n",
        "    y_train = pd.Series(y_train)\n",
        "    y_test = pd.Series(y_test)\n",
        "else:\n",
        "    # Fallback to sklearn train_test_split with stratification\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        df['cleaned_text'], \n",
        "        df['label_encoded'],\n",
        "        test_size=0.2, \n",
        "        random_state=42, \n",
        "        stratify=df['label_encoded']\n",
        "    )\n",
        "\n",
        "print(f'Training set size: {len(X_train)}')\n",
        "print(f'Test set size: {len(X_test)}')\n",
        "print(f'Training label distribution:\\n{y_train.value_counts()}')\n",
        "\n",
        "# Remove NaN values (if any) from training and test sets\n",
        "print('\\nChecking for NaN values...')\n",
        "train_nan_mask = X_train.notna()\n",
        "test_nan_mask = X_test.notna()\n",
        "\n",
        "if not train_nan_mask.all():\n",
        "    print(f'⚠️  Found {(~train_nan_mask).sum()} NaN values in training set - removing them')\n",
        "    X_train = X_train[train_nan_mask]\n",
        "    y_train = y_train[train_nan_mask]\n",
        "\n",
        "if not test_nan_mask.all():\n",
        "    print(f'⚠️  Found {(~test_nan_mask).sum()} NaN values in test set - removing them')\n",
        "    X_test = X_test[test_nan_mask]\n",
        "    y_test = y_test[test_nan_mask]\n",
        "\n",
        "print(f'\\nAfter cleaning:')\n",
        "print(f'Training set size: {len(X_train)}')\n",
        "print(f'Test set size: {len(X_test)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Experiment 1: GRU + TF-IDF\n",
        "\n",
        "**Architecture:** Dense → RepeatVector → Dual GRU Layers\n",
        "\n",
        "**Rationale:** \n",
        "- TF-IDF sparse features work better with dense compression first\n",
        "- RepeatVector creates artificial time steps for GRU processing\n",
        "- Class weights handle the 6.5:1 imbalance ratio\n",
        "\n",
        "**Citation:** Cho et al. (2014) - Learning Phrase Representations using RNN Encoder-Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build GRU model for TF-IDF with improved architecture\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, GRU, RepeatVector\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def build_gru_tfidf_model(input_dim, gru_units=64, dropout_rate=0.3, learning_rate=0.001):\n",
        "    \"\"\"\n",
        "    Improved GRU model for TF-IDF features.\n",
        "    Uses Dense layer to compress features, then repeats for GRU processing.\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        # Dense layer to learn compressed representation\n",
        "        Dense(256, activation='relu', input_shape=(input_dim,)),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        \n",
        "        # Reshape for GRU: repeat the vector into a short sequence\n",
        "        RepeatVector(10),  # Create 10 time steps\n",
        "        \n",
        "        # GRU layers\n",
        "        GRU(gru_units, return_sequences=True, dropout=dropout_rate),\n",
        "        GRU(gru_units // 2, return_sequences=False, dropout=dropout_rate),\n",
        "        \n",
        "        # Output layers\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    \n",
        "    # Use custom metrics with proper names\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=learning_rate),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            tf.keras.metrics.Precision(name='precision'),\n",
        "            tf.keras.metrics.Recall(name='recall')\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "set_seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Build model\n",
        "model_tfidf = build_gru_tfidf_model(\n",
        "    input_dim=X_train_tfidf.shape[1],\n",
        "    gru_units=64,\n",
        "    dropout_rate=0.3,\n",
        "    learning_rate=0.001\n",
        ")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"MODEL ARCHITECTURE\")\n",
        "print(\"=\"*60)\n",
        "print(model_tfidf.summary())\n",
        "\n",
        "# Setup callbacks\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)\n",
        "\n",
        "# Train model with class weights\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING GRU + TF-IDF\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Using class weights: Ham={class_weight_dict[0]:.3f}, Spam={class_weight_dict[1]:.3f}\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "history_tfidf = model_tfidf.fit(\n",
        "    X_train_tfidf, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    class_weight=class_weight_dict,\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "training_time_tfidf = time.time() - start_time\n",
        "\n",
        "print(f'\\n✓ Training completed in {training_time_tfidf:.2f}s')\n",
        "\n",
        "# Make predictions\n",
        "y_pred_tfidf_prob = model_tfidf.predict(X_test_tfidf, verbose=0)\n",
        "y_pred_tfidf = (y_pred_tfidf_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "print(f'\\nPrediction distribution:')\n",
        "print(f'  Ham (0):  {(y_pred_tfidf == 0).sum()}/{len(y_pred_tfidf)}')\n",
        "print(f'  Spam (1): {(y_pred_tfidf == 1).sum()}/{len(y_pred_tfidf)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate GRU + TF-IDF Model\n",
        "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
        "\n",
        "evaluator = ModelEvaluator(class_names=['ham', 'spam'])\n",
        "\n",
        "metrics_tfidf = evaluator.evaluate(\n",
        "    y_test, y_pred_tfidf,\n",
        "    model_name='GRU',\n",
        "    embedding_name='TF-IDF',\n",
        "    training_time=training_time_tfidf\n",
        ")\n",
        "\n",
        "evaluator.print_metrics(metrics_tfidf)\n",
        "\n",
        "# Print detailed classification report\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DETAILED CLASSIFICATION REPORT\")\n",
        "print(\"=\"*60)\n",
        "print(classification_report(y_test, y_pred_tfidf, target_names=['ham', 'spam'], digits=4))\n",
        "\n",
        "# Per-class performance\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PER-CLASS PERFORMANCE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Ham Detection:\")\n",
        "print(f\"  Precision: {precision_score(y_test, y_pred_tfidf, pos_label=0):.4f}\")\n",
        "print(f\"  Recall:    {recall_score(y_test, y_pred_tfidf, pos_label=0):.4f}\")\n",
        "print(f\"  F1-Score:  {f1_score(y_test, y_pred_tfidf, pos_label=0):.4f}\")\n",
        "\n",
        "print(f\"\\nSpam Detection (TARGET):\")\n",
        "print(f\"  Precision: {precision_score(y_test, y_pred_tfidf, pos_label=1, zero_division=0):.4f}\")\n",
        "print(f\"  Recall:    {recall_score(y_test, y_pred_tfidf, pos_label=1):.4f}\")\n",
        "print(f\"  F1-Score:  {f1_score(y_test, y_pred_tfidf, pos_label=1, zero_division=0):.4f}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Plot confusion matrix\n",
        "evaluator.plot_confusion_matrix(\n",
        "    y_test, y_pred_tfidf,\n",
        "    title='GRU + TF-IDF - Confusion Matrix'\n",
        ")\n",
        "\n",
        "# Plot training history\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "\n",
        "# Accuracy\n",
        "axes[0, 0].plot(history_tfidf.history['accuracy'], label='Train', linewidth=2)\n",
        "axes[0, 0].plot(history_tfidf.history['val_accuracy'], label='Validation', linewidth=2)\n",
        "axes[0, 0].set_xlabel('Epoch', fontsize=11)\n",
        "axes[0, 0].set_ylabel('Accuracy', fontsize=11)\n",
        "axes[0, 0].set_title('Accuracy', fontsize=13, fontweight='bold')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# Loss\n",
        "axes[0, 1].plot(history_tfidf.history['loss'], label='Train', linewidth=2)\n",
        "axes[0, 1].plot(history_tfidf.history['val_loss'], label='Validation', linewidth=2)\n",
        "axes[0, 1].set_xlabel('Epoch', fontsize=11)\n",
        "axes[0, 1].set_ylabel('Loss', fontsize=11)\n",
        "axes[0, 1].set_title('Loss', fontsize=13, fontweight='bold')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "# Precision\n",
        "axes[1, 0].plot(history_tfidf.history['precision'], label='Train', linewidth=2)\n",
        "axes[1, 0].plot(history_tfidf.history['val_precision'], label='Validation', linewidth=2)\n",
        "axes[1, 0].set_xlabel('Epoch', fontsize=11)\n",
        "axes[1, 0].set_ylabel('Precision', fontsize=11)\n",
        "axes[1, 0].set_title('Precision', fontsize=13, fontweight='bold')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(alpha=0.3)\n",
        "\n",
        "# Recall\n",
        "axes[1, 1].plot(history_tfidf.history['recall'], label='Train', linewidth=2)\n",
        "axes[1, 1].plot(history_tfidf.history['val_recall'], label='Validation', linewidth=2)\n",
        "axes[1, 1].set_xlabel('Epoch', fontsize=11)\n",
        "axes[1, 1].set_ylabel('Recall', fontsize=11)\n",
        "axes[1, 1].set_title('Recall', fontsize=13, fontweight='bold')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(alpha=0.3)\n",
        "\n",
        "plt.suptitle('GRU + TF-IDF Training History', fontsize=16, fontweight='bold', y=1.00)\n",
        "plt.tight_layout()\n",
        "\n",
        "if not IS_KAGGLE:\n",
        "    os.makedirs(os.path.join(OUTPUT_DIR, 'figures'), exist_ok=True)\n",
        "    plt.savefig(os.path.join(OUTPUT_DIR, 'figures', 'member4_tfidf_history.png'), dpi=300, bbox_inches='tight')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Experiment 2: GRU + Skip-gram (Word2Vec)\n",
        "\n",
        "**Architecture:** Dense → RepeatVector → Dual GRU (applied to Word2Vec embeddings)\n",
        "\n",
        "**Rationale:** \n",
        "- Skip-gram captures semantic word relationships through context prediction\n",
        "- Dense 100-dimensional vectors work naturally with GRU\n",
        "- Document averaging creates fixed-length representation\n",
        "\n",
        "**Citation:** Mikolov et al. (2013) - Efficient Estimation of Word Representations in Vector Space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare Skip-gram embeddings (Word2Vec with sg=1)\n",
        "print('Preparing Skip-gram embeddings...\\n')\n",
        "\n",
        "# Tokenize texts for Word2Vec\n",
        "preprocessor_w2v = TextPreprocessor(\n",
        "    lowercase=True,\n",
        "    remove_punctuation=True,\n",
        "    remove_stopwords=True,\n",
        "    lemmatization=True\n",
        ")\n",
        "\n",
        "X_train_tokens = X_train.apply(lambda x: preprocessor_w2v.preprocess(x, return_tokens=True)).tolist()\n",
        "X_test_tokens = X_test.apply(lambda x: preprocessor_w2v.preprocess(x, return_tokens=True)).tolist()\n",
        "\n",
        "# Train Skip-gram Word2Vec model\n",
        "skipgram = Word2VecEmbedding(\n",
        "    vector_size=100,\n",
        "    window=5,\n",
        "    min_count=2,\n",
        "    sg=1,  # Skip-gram\n",
        "    workers=4,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "print('Training Skip-gram model...')\n",
        "skipgram.train(X_train_tokens)\n",
        "print(f'Skip-gram model trained with vocabulary size: {len(skipgram.model.wv)}')\n",
        "\n",
        "# Transform to document vectors\n",
        "X_train_skipgram = skipgram.transform(X_train_tokens, method='mean')\n",
        "X_test_skipgram = skipgram.transform(X_test_tokens, method='mean')\n",
        "\n",
        "print(f'\\nSkip-gram embeddings shape: {X_train_skipgram.shape}')\n",
        "\n",
        "# Build and train GRU with Skip-gram (using improved architecture)\n",
        "def build_gru_word2vec_model(input_dim, gru_units=64, dropout_rate=0.3, learning_rate=0.001):\n",
        "    \"\"\"\n",
        "    Improved GRU model for Word2Vec features.\n",
        "    Uses Dense compression + RepeatVector approach like TF-IDF model.\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        # Dense layer to learn compressed representation\n",
        "        Dense(128, activation='relu', input_shape=(input_dim,)),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        \n",
        "        # Reshape for GRU: repeat the vector into a short sequence\n",
        "        RepeatVector(10),  # Create 10 time steps\n",
        "        \n",
        "        # GRU layers\n",
        "        GRU(gru_units, return_sequences=True, dropout=dropout_rate),\n",
        "        GRU(gru_units // 2, return_sequences=False, dropout=dropout_rate),\n",
        "        \n",
        "        # Output layers\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    \n",
        "    # Use custom metrics with proper names (matching TF-IDF model)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=learning_rate),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            tf.keras.metrics.Precision(name='precision'),\n",
        "            tf.keras.metrics.Recall(name='recall')\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Train model with class weights\n",
        "print('\\n' + '='*60)\n",
        "print('TRAINING GRU + Skip-gram')\n",
        "print('='*60)\n",
        "print(f\"Using class weights: Ham={class_weight_dict[0]:.3f}, Spam={class_weight_dict[1]:.3f}\")\n",
        "print('='*60 + '\\n')\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "history_skipgram = model_skipgram.fit(\n",
        "    X_train_skipgram, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    class_weight=class_weight_dict,  # ADD CLASS WEIGHTS\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "training_time_skipgram = time.time() - start_time\n",
        "print(f'\\n✓ Training completed in {training_time_skipgram:.2f}s')\n",
        "\n",
        "# Make predictions\n",
        "y_pred_skipgram_prob = model_skipgram.predict(X_test_skipgram)\n",
        "y_pred_skipgram = (y_pred_skipgram_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "# Evaluate\n",
        "metrics_skipgram = evaluator.evaluate(\n",
        "    y_test, y_pred_skipgram,\n",
        "    model_name='GRU',\n",
        "    embedding_name='Skip-gram',\n",
        "    training_time=training_time_skipgram\n",
        ")\n",
        "\n",
        "evaluator.print_metrics(metrics_skipgram)\n",
        "\n",
        "# Plot confusion matrix\n",
        "fig_path = os.path.join(OUTPUT_DIR, 'figures', 'member4_skipgram_cm.png') if not IS_KAGGLE else None\n",
        "if not IS_KAGGLE:\n",
        "    os.makedirs(os.path.join(OUTPUT_DIR, 'figures'), exist_ok=True)\n",
        "\n",
        "evaluator.plot_confusion_matrix(\n",
        "    y_test, y_pred_skipgram,\n",
        "    title='GRU + Skip-gram - Confusion Matrix',\n",
        "    save_path=fig_path\n",
        ")\n",
        "\n",
        "# Plot training history\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "axes[0].plot(history_skipgram.history['accuracy'], label='Train Accuracy')\n",
        "axes[0].plot(history_skipgram.history['val_accuracy'], label='Val Accuracy')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Accuracy')\n",
        "axes[0].set_title('GRU + Skip-gram - Training History (Accuracy)')\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "axes[1].plot(history_skipgram.history['loss'], label='Train Loss')\n",
        "axes[1].plot(history_skipgram.history['val_loss'], label='Val Loss')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Loss')\n",
        "axes[1].set_title('GRU + Skip-gram - Training History (Loss)')\n",
        "axes[1].legend()\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "if not IS_KAGGLE:\n",
        "    os.makedirs(os.path.join(OUTPUT_DIR, 'figures'), exist_ok=True)\n",
        "    plt.savefig(os.path.join(OUTPUT_DIR, 'figures', 'member4_skipgram_history.png'), dpi=300, bbox_inches='tight')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Experiment 3: GRU + CBOW (Word2Vec)\n",
        "\n",
        "**Architecture:** Dense → RepeatVector → Dual GRU (applied to CBOW embeddings)\n",
        "\n",
        "**Rationale:** \n",
        "- CBOW predicts target words from context (opposite of Skip-gram)\n",
        "- Faster training than Skip-gram\n",
        "- Works well for smaller datasets\n",
        "\n",
        "**Citation:** Mikolov et al. (2013)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare CBOW embeddings (Word2Vec with sg=0)\n",
        "print('Preparing CBOW embeddings...\\n')\n",
        "\n",
        "# Train CBOW Word2Vec model\n",
        "cbow = Word2VecEmbedding(\n",
        "    vector_size=100,\n",
        "    window=5,\n",
        "    min_count=2,\n",
        "    sg=0,  # CBOW\n",
        "    workers=4,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "print('Training CBOW model...')\n",
        "cbow.train(X_train_tokens)\n",
        "print(f'CBOW model trained with vocabulary size: {len(cbow.model.wv)}')\n",
        "\n",
        "# Transform to document vectors\n",
        "X_train_cbow = cbow.transform(X_train_tokens, method='mean')\n",
        "X_test_cbow = cbow.transform(X_test_tokens, method='mean')\n",
        "\n",
        "print(f'\\nCBOW embeddings shape: {X_train_cbow.shape}')\n",
        "\n",
        "# Build and train GRU with CBOW\n",
        "set_seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model_cbow = build_gru_word2vec_model(\n",
        "    input_dim=X_train_cbow.shape[1],\n",
        "    gru_units=64,\n",
        "    dropout_rate=0.3,\n",
        "    learning_rate=0.001\n",
        ")\n",
        "\n",
        "print('\\n', model_cbow.summary())\n",
        "\n",
        "# Train model with class weights\n",
        "print('\\n' + '='*60)\n",
        "print('TRAINING GRU + CBOW')\n",
        "print('='*60)\n",
        "print(f\"Using class weights: Ham={class_weight_dict[0]:.3f}, Spam={class_weight_dict[1]:.3f}\")\n",
        "print('='*60 + '\\n')\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "history_cbow = model_cbow.fit(\n",
        "    X_train_cbow, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    class_weight=class_weight_dict,  # ADD CLASS WEIGHTS\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "training_time_cbow = time.time() - start_time\n",
        "print(f'\\n✓ Training completed in {training_time_cbow:.2f}s')\n",
        "\n",
        "# Make predictions\n",
        "y_pred_cbow_prob = model_cbow.predict(X_test_cbow)\n",
        "y_pred_cbow = (y_pred_cbow_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "# Evaluate\n",
        "metrics_cbow = evaluator.evaluate(\n",
        "    y_test, y_pred_cbow,\n",
        "    model_name='GRU',\n",
        "    embedding_name='CBOW',\n",
        "    training_time=training_time_cbow\n",
        ")\n",
        "\n",
        "evaluator.print_metrics(metrics_cbow)\n",
        "\n",
        "# Plot confusion matrix\n",
        "fig_path = os.path.join(OUTPUT_DIR, 'figures', 'member4_cbow_cm.png') if not IS_KAGGLE else None\n",
        "if not IS_KAGGLE:\n",
        "    os.makedirs(os.path.join(OUTPUT_DIR, 'figures'), exist_ok=True)\n",
        "\n",
        "evaluator.plot_confusion_matrix(\n",
        "    y_test, y_pred_cbow,\n",
        "    title='GRU + CBOW - Confusion Matrix',\n",
        "    save_path=fig_path\n",
        ")\n",
        "\n",
        "# Plot training history\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "axes[0].plot(history_cbow.history['accuracy'], label='Train Accuracy')\n",
        "axes[0].plot(history_cbow.history['val_accuracy'], label='Val Accuracy')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Accuracy')\n",
        "axes[0].set_title('GRU + CBOW - Training History (Accuracy)')\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "axes[1].plot(history_cbow.history['loss'], label='Train Loss')\n",
        "axes[1].plot(history_cbow.history['val_loss'], label='Val Loss')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Loss')\n",
        "axes[1].set_title('GRU + CBOW - Training History (Loss)')\n",
        "axes[1].legend()\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "if not IS_KAGGLE:\n",
        "    os.makedirs(os.path.join(OUTPUT_DIR, 'figures'), exist_ok=True)\n",
        "    plt.savefig(os.path.join(OUTPUT_DIR, 'figures', 'member4_cbow_history.png'), dpi=300, bbox_inches='tight')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Results Summary and Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save all results to CSV\n",
        "# Create directories (both for Kaggle and local)\n",
        "os.makedirs(os.path.join(OUTPUT_DIR, 'tables'), exist_ok=True)\n",
        "if not IS_KAGGLE:\n",
        "    os.makedirs(os.path.join(OUTPUT_DIR, 'figures'), exist_ok=True)\n",
        "\n",
        "results_path = os.path.join(OUTPUT_DIR, 'tables', 'member4_results.csv')\n",
        "results_df = evaluator.save_results_table(filepath=results_path)\n",
        "\n",
        "print('\\nResults Summary:')\n",
        "print('=' * 80)\n",
        "print(results_df)\n",
        "\n",
        "# Create comparison visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "embeddings = results_df['embedding'].values\n",
        "metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1_score']\n",
        "\n",
        "for idx, metric in enumerate(metrics_to_plot):\n",
        "    row = idx // 2\n",
        "    col = idx % 2\n",
        "    \n",
        "    values = results_df[metric].values\n",
        "    bars = axes[row, col].bar(embeddings, values, color=['skyblue', 'lightcoral', 'lightgreen'])\n",
        "    \n",
        "    axes[row, col].set_ylabel(metric.replace('_', ' ').title(), fontsize=11)\n",
        "    axes[row, col].set_title(f'GRU - {metric.replace(\"_\", \" \").title()} Comparison', \n",
        "                             fontsize=13, fontweight='bold')\n",
        "    axes[row, col].set_ylim([0, 1.05])\n",
        "    axes[row, col].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        axes[row, col].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                           f'{height:.4f}',\n",
        "                           ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "if not IS_KAGGLE:\n",
        "    plt.savefig(os.path.join(OUTPUT_DIR, 'figures', 'member4_comparison.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Training time comparison\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "bars = ax.bar(embeddings, results_df['training_time'].values, color=['skyblue', 'lightcoral', 'lightgreen'])\n",
        "ax.set_ylabel('Time (seconds)', fontsize=12)\n",
        "ax.set_title('GRU - Training Time Comparison', fontsize=14, fontweight='bold')\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "           f'{height:.2f}s',\n",
        "           ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "\n",
        "if not IS_KAGGLE:\n",
        "    plt.savefig(os.path.join(OUTPUT_DIR, 'figures', 'member4_training_time.png'), dpi=300, bbox_inches='tight')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Hyperparameter Tuning (Optional but Recommended)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameter Tuning for Best Embedding\n",
        "# Based on the results above, we'll tune the best performing embedding\n",
        "\n",
        "# Find best embedding\n",
        "best_embedding = results_df.loc[results_df['f1_score'].idxmax(), 'embedding']\n",
        "print(f'Best performing embedding: {best_embedding}')\n",
        "print(f'Best F1 Score: {results_df[\"f1_score\"].max():.4f}')\n",
        "print('\\nPerforming hyperparameter tuning...\\n')\n",
        "\n",
        "# Select the appropriate data based on best embedding\n",
        "if best_embedding == 'TF-IDF':\n",
        "    X_train_best = X_train_tfidf\n",
        "    X_test_best = X_test_tfidf\n",
        "elif best_embedding == 'Skip-gram':\n",
        "    X_train_best = X_train_skipgram\n",
        "    X_test_best = X_test_skipgram\n",
        "else:  # CBOW\n",
        "    X_train_best = X_train_cbow\n",
        "    X_test_best = X_test_cbow\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'gru_units': [32, 64, 128],\n",
        "    'dropout_rate': [0.2, 0.3, 0.4],\n",
        "    'learning_rate': [0.0001, 0.001, 0.01],\n",
        "    'batch_size': [16, 32, 64]\n",
        "}\n",
        "\n",
        "# Manual grid search (since Keras models don't work well with sklearn GridSearchCV)\n",
        "best_score = 0\n",
        "best_params = {}\n",
        "tuning_results = []\n",
        "\n",
        "print('Testing hyperparameter combinations...\\n')\n",
        "total_combinations = len(param_grid['gru_units']) * len(param_grid['dropout_rate']) * len(param_grid['learning_rate'])\n",
        "current = 0\n",
        "\n",
        "for gru_units in param_grid['gru_units']:\n",
        "    for dropout_rate in param_grid['dropout_rate']:\n",
        "        for learning_rate in param_grid['learning_rate']:\n",
        "            current += 1\n",
        "            print(f'Testing combination {current}/{total_combinations}: GRU={gru_units}, Dropout={dropout_rate}, LR={learning_rate}')\n",
        "            \n",
        "            # Build model\n",
        "            set_seed(42)\n",
        "            tf.random.set_seed(42)\n",
        "            \n",
        "            if best_embedding == 'TF-IDF':\n",
        "                model_tune = build_gru_tfidf_model(\n",
        "                    input_dim=X_train_best.shape[1],\n",
        "                    gru_units=gru_units,\n",
        "                    dropout_rate=dropout_rate,\n",
        "                    learning_rate=learning_rate\n",
        "                )\n",
        "            else:\n",
        "                model_tune = build_gru_word2vec_model(\n",
        "                    input_dim=X_train_best.shape[1],\n",
        "                    gru_units=gru_units,\n",
        "                    dropout_rate=dropout_rate,\n",
        "                    learning_rate=learning_rate\n",
        "                )\n",
        "            \n",
        "            # Train with early stopping\n",
        "            early_stop_tune = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "            \n",
        "            history_tune = model_tune.fit(\n",
        "                X_train_best, y_train,\n",
        "                validation_split=0.2,\n",
        "                epochs=20,\n",
        "                batch_size=32,\n",
        "                callbacks=[early_stop_tune],\n",
        "                verbose=0\n",
        "            )\n",
        "            \n",
        "            # Evaluate on validation set\n",
        "            val_loss, val_acc, val_precision, val_recall = model_tune.evaluate(\n",
        "                X_train_best[int(len(X_train_best)*0.8):], \n",
        "                y_train.values[int(len(y_train)*0.8):],\n",
        "                verbose=0\n",
        "            )\n",
        "            \n",
        "            # Calculate F1 score\n",
        "            val_f1 = 2 * (val_precision * val_recall) / (val_precision + val_recall + 1e-7)\n",
        "            \n",
        "            tuning_results.append({\n",
        "                'gru_units': gru_units,\n",
        "                'dropout_rate': dropout_rate,\n",
        "                'learning_rate': learning_rate,\n",
        "                'val_accuracy': val_acc,\n",
        "                'val_precision': val_precision,\n",
        "                'val_recall': val_recall,\n",
        "                'val_f1': val_f1\n",
        "            })\n",
        "            \n",
        "            print(f'  Val Accuracy: {val_acc:.4f}, Val F1: {val_f1:.4f}\\n')\n",
        "            \n",
        "            # Track best model\n",
        "            if val_f1 > best_score:\n",
        "                best_score = val_f1\n",
        "                best_params = {\n",
        "                    'gru_units': gru_units,\n",
        "                    'dropout_rate': dropout_rate,\n",
        "                    'learning_rate': learning_rate\n",
        "                }\n",
        "\n",
        "print('\\n' + '='*80)\n",
        "print('BEST HYPERPARAMETERS:')\n",
        "print('='*80)\n",
        "for param, value in best_params.items():\n",
        "    print(f'{param}: {value}')\n",
        "print(f'Best Validation F1 Score: {best_score:.4f}')\n",
        "print('='*80)\n",
        "\n",
        "# Train final model with best hyperparameters\n",
        "print('\\nTraining final model with best hyperparameters...')\n",
        "set_seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "if best_embedding == 'TF-IDF':\n",
        "    model_final = build_gru_tfidf_model(\n",
        "        input_dim=X_train_best.shape[1],\n",
        "        **best_params\n",
        "    )\n",
        "else:\n",
        "    model_final = build_gru_word2vec_model(\n",
        "        input_dim=X_train_best.shape[1],\n",
        "        **best_params\n",
        "    )\n",
        "\n",
        "history_final = model_final.fit(\n",
        "    X_train_best, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred_final_prob = model_final.predict(X_test_best)\n",
        "y_pred_final = (y_pred_final_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "metrics_final = evaluator.evaluate(\n",
        "    y_test, y_pred_final,\n",
        "    model_name='GRU (Tuned)',\n",
        "    embedding_name=best_embedding,\n",
        "    training_time=0\n",
        ")\n",
        "\n",
        "print('\\n' + '='*80)\n",
        "print('FINAL TUNED MODEL RESULTS:')\n",
        "evaluator.print_metrics(metrics_final)\n",
        "\n",
        "# Save tuning results\n",
        "tuning_df = pd.DataFrame(tuning_results)\n",
        "tuning_path = os.path.join(OUTPUT_DIR, 'tables', 'member4_hyperparameter_tuning.csv')\n",
        "tuning_df.to_csv(tuning_path, index=False)\n",
        "print(f'\\nHyperparameter tuning results saved to {tuning_path}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Conclusions and Observations\n",
        "\n",
        "**Key Findings:**\n",
        "\n",
        "Based on experiments with GRU models across three embeddings (TF-IDF, Skip-gram, CBOW), we can compare performance and draw conclusions about which approach works best for SMS spam classification."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
